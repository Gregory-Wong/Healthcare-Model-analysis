{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FMsNSoLyrclM",
        "KDHwxSjSrWBY",
        "XrPEo7iWrJ4V",
        "Htxbk9zQrC7B",
        "ZYIxGJKMBqJu",
        "64W7Bpfmq01e",
        "zNCjCk1szAtI",
        "AUGiEz_mqv0T",
        "kYgT-g0Kqp0u",
        "9prpKaL1qllx",
        "SRU1eA2yqe3N",
        "kbNIKck0qXux",
        "KIjzLsfcrwXJ",
        "i8Xl24zj9Ava",
        "6Jnxpfzo9jfc",
        "op-0NFA6-PU4",
        "JFGIiWy--TbB",
        "OCxleDgS_CpY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gregory-Wong/Healthcare-Model-analysis/blob/main/diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9JKJ-NNS4Rr"
      },
      "source": [
        "Import file as a csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "OKS3vJKCQKxU",
        "outputId": "19c032db-0960-40a6-e993-8544b49fc02d"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63a3bfc3-e332-41aa-8b50-971e8bc6791d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63a3bfc3-e332-41aa-8b50-971e8bc6791d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ClassDiabetesDataSet.csv to ClassDiabetesDataSet.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMsNSoLyrclM"
      },
      "source": [
        "# Inital Data Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LEt48PIQR6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "05536298-65b9-4c78-c8f1-9ad5d5ae2bbd"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(io.BytesIO(uploaded ['ClassDiabetesDataSet.csv']))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>payer_code</th>\n",
              "      <th>medical_specialty</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>diag_1</th>\n",
              "      <th>diag_2</th>\n",
              "      <th>diag_3</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>max_glu_serum</th>\n",
              "      <th>A1Cresult</th>\n",
              "      <th>encounter_id.1</th>\n",
              "      <th>metformin</th>\n",
              "      <th>repaglinide</th>\n",
              "      <th>nateglinide</th>\n",
              "      <th>chlorpropamide</th>\n",
              "      <th>glimepiride</th>\n",
              "      <th>acetohexamide</th>\n",
              "      <th>glipizide</th>\n",
              "      <th>glyburide</th>\n",
              "      <th>tolbutamide</th>\n",
              "      <th>pioglitazone</th>\n",
              "      <th>rosiglitazone</th>\n",
              "      <th>acarbose</th>\n",
              "      <th>miglitol</th>\n",
              "      <th>troglitazone</th>\n",
              "      <th>tolazamide</th>\n",
              "      <th>examide</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2278392</td>\n",
              "      <td>8222157</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pediatrics-Endocrinology</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.83</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2278392</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149190</td>\n",
              "      <td>55629189</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.01</td>\n",
              "      <td>255.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>149190</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64410</td>\n",
              "      <td>86047875</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>648.00</td>\n",
              "      <td>250.00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>64410</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500364</td>\n",
              "      <td>82442376</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>250.43</td>\n",
              "      <td>403.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>500364</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16680</td>\n",
              "      <td>42519267</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>197.00</td>\n",
              "      <td>157.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>16680</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65529</th>\n",
              "      <td>182739006</td>\n",
              "      <td>2583225</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>65</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cardiology</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>427.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>70.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>182739006</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65530</th>\n",
              "      <td>182740098</td>\n",
              "      <td>47162142</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>CM</td>\n",
              "      <td>Family/GeneralPractice</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>812.00</td>\n",
              "      <td>424.00</td>\n",
              "      <td>888.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>182740098</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65531</th>\n",
              "      <td>182740320</td>\n",
              "      <td>87180561</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>MC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>786.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>401.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>182740320</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65532</th>\n",
              "      <td>182742096</td>\n",
              "      <td>77729049</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>UN</td>\n",
              "      <td>Orthopedics</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>996.00</td>\n",
              "      <td>43.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>182742096</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65533</th>\n",
              "      <td>182742786</td>\n",
              "      <td>95340582</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>SP</td>\n",
              "      <td>Emergency/Trauma</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>182742786</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65534 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       encounter_id  patient_nbr             race  ... change  diabetesMed  readmitted\n",
              "0           2278392      8222157        Caucasian  ...     No           No          NO\n",
              "1            149190     55629189        Caucasian  ...     Ch          Yes         >30\n",
              "2             64410     86047875  AfricanAmerican  ...     No          Yes          NO\n",
              "3            500364     82442376        Caucasian  ...     Ch          Yes          NO\n",
              "4             16680     42519267        Caucasian  ...     Ch          Yes          NO\n",
              "...             ...          ...              ...  ...    ...          ...         ...\n",
              "65529     182739006      2583225        Caucasian  ...     Ch          Yes          NO\n",
              "65530     182740098     47162142        Caucasian  ...     No          Yes          NO\n",
              "65531     182740320     87180561  AfricanAmerican  ...     No           No          NO\n",
              "65532     182742096     77729049        Caucasian  ...     No          Yes         >30\n",
              "65533     182742786     95340582        Caucasian  ...     No           No          NO\n",
              "\n",
              "[65534 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDHwxSjSrWBY"
      },
      "source": [
        "# Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-6aNYYITFgz"
      },
      "source": [
        "Identify a list of columns to drop \n",
        "\n",
        "Add column name to a list \n",
        "\n",
        "Drop all unwanted columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzi0vzVe-XoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aebe252-1b63-4045-f2f5-3105e1b9c7e0"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight',\n",
              "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
              "       'time_in_hospital', 'payer_code', 'medical_specialty',\n",
              "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
              "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
              "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
              "       'encounter_id.1', 'metformin', 'repaglinide', 'nateglinide',\n",
              "       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
              "       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
              "       'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton',\n",
              "       'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
              "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
              "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kra3ww649JOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc199bb-3d12-4f84-f11f-20a1120d96a9"
      },
      "source": [
        "#create a list of unwanted columns\n",
        "columns_to_drop=['encounter_id', 'patient_nbr', 'payer_code', 'medical_specialty' , 'encounter_id.1','weight']\n",
        "columns_to_drop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encounter_id',\n",
              " 'patient_nbr',\n",
              " 'payer_code',\n",
              " 'medical_specialty',\n",
              " 'encounter_id.1',\n",
              " 'weight']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGyRFuxZka6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "a2dad44b-c180-4dc3-8b0f-89834ad0b489"
      },
      "source": [
        "#remove unwanted columns\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>diag_1</th>\n",
              "      <th>diag_2</th>\n",
              "      <th>diag_3</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>max_glu_serum</th>\n",
              "      <th>A1Cresult</th>\n",
              "      <th>metformin</th>\n",
              "      <th>repaglinide</th>\n",
              "      <th>nateglinide</th>\n",
              "      <th>chlorpropamide</th>\n",
              "      <th>glimepiride</th>\n",
              "      <th>acetohexamide</th>\n",
              "      <th>glipizide</th>\n",
              "      <th>glyburide</th>\n",
              "      <th>tolbutamide</th>\n",
              "      <th>pioglitazone</th>\n",
              "      <th>rosiglitazone</th>\n",
              "      <th>acarbose</th>\n",
              "      <th>miglitol</th>\n",
              "      <th>troglitazone</th>\n",
              "      <th>tolazamide</th>\n",
              "      <th>examide</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.83</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.01</td>\n",
              "      <td>255.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>648.00</td>\n",
              "      <td>250.00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>250.43</td>\n",
              "      <td>403.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>197.00</td>\n",
              "      <td>157.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65529</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>427.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>70.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65530</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>812.00</td>\n",
              "      <td>424.00</td>\n",
              "      <td>888.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65531</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>786.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>401.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65532</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>85</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>996.00</td>\n",
              "      <td>43.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65533</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65534 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  race  gender  age  ...  change  diabetesMed  readmitted\n",
              "0            Caucasian  Female    5  ...      No           No          NO\n",
              "1            Caucasian  Female   15  ...      Ch          Yes         >30\n",
              "2      AfricanAmerican  Female   25  ...      No          Yes          NO\n",
              "3            Caucasian    Male   35  ...      Ch          Yes          NO\n",
              "4            Caucasian    Male   45  ...      Ch          Yes          NO\n",
              "...                ...     ...  ...  ...     ...          ...         ...\n",
              "65529        Caucasian  Female   65  ...      Ch          Yes          NO\n",
              "65530        Caucasian  Female   75  ...      No          Yes          NO\n",
              "65531  AfricanAmerican  Female   75  ...      No           No          NO\n",
              "65532        Caucasian  Female   85  ...      No          Yes         >30\n",
              "65533        Caucasian    Male   55  ...      No           No          NO\n",
              "\n",
              "[65534 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTQW6Mo6l1L-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125fca8f-180a-475d-c6a7-625431fe5f17"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 65534 entries, 0 to 65533\n",
            "Data columns (total 45 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   race                      64201 non-null  object \n",
            " 1   gender                    65534 non-null  object \n",
            " 2   age                       65534 non-null  int64  \n",
            " 3   admission_type_id         65534 non-null  int64  \n",
            " 4   discharge_disposition_id  65534 non-null  int64  \n",
            " 5   admission_source_id       65534 non-null  int64  \n",
            " 6   time_in_hospital          65534 non-null  int64  \n",
            " 7   num_lab_procedures        65534 non-null  int64  \n",
            " 8   num_procedures            65534 non-null  int64  \n",
            " 9   num_medications           65534 non-null  int64  \n",
            " 10  number_outpatient         65534 non-null  int64  \n",
            " 11  number_emergency          65534 non-null  int64  \n",
            " 12  number_inpatient          65534 non-null  int64  \n",
            " 13  diag_1                    65517 non-null  float64\n",
            " 14  diag_2                    65234 non-null  float64\n",
            " 15  diag_3                    64323 non-null  float64\n",
            " 16  number_diagnoses          65534 non-null  int64  \n",
            " 17  max_glu_serum             65534 non-null  object \n",
            " 18  A1Cresult                 65534 non-null  object \n",
            " 19  metformin                 65534 non-null  object \n",
            " 20  repaglinide               65534 non-null  object \n",
            " 21  nateglinide               65534 non-null  object \n",
            " 22  chlorpropamide            65534 non-null  object \n",
            " 23  glimepiride               65534 non-null  object \n",
            " 24  acetohexamide             65534 non-null  object \n",
            " 25  glipizide                 65534 non-null  object \n",
            " 26  glyburide                 65534 non-null  object \n",
            " 27  tolbutamide               65534 non-null  object \n",
            " 28  pioglitazone              65534 non-null  object \n",
            " 29  rosiglitazone             65534 non-null  object \n",
            " 30  acarbose                  65534 non-null  object \n",
            " 31  miglitol                  65534 non-null  object \n",
            " 32  troglitazone              65534 non-null  object \n",
            " 33  tolazamide                65534 non-null  object \n",
            " 34  examide                   65534 non-null  object \n",
            " 35  citoglipton               65534 non-null  object \n",
            " 36  insulin                   65534 non-null  object \n",
            " 37  glyburide-metformin       65534 non-null  object \n",
            " 38  glipizide-metformin       65534 non-null  object \n",
            " 39  glimepiride-pioglitazone  65534 non-null  object \n",
            " 40  metformin-rosiglitazone   65534 non-null  object \n",
            " 41  metformin-pioglitazone    65534 non-null  object \n",
            " 42  change                    65534 non-null  object \n",
            " 43  diabetesMed               65534 non-null  object \n",
            " 44  readmitted                65534 non-null  object \n",
            "dtypes: float64(3), int64(12), object(30)\n",
            "memory usage: 22.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq3ofcgTZiAh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "b6b4050d-90c3-48af-815b-3b32abcf36b3"
      },
      "source": [
        "df_modified=df\n",
        "df_modified"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>diag_1</th>\n",
              "      <th>diag_2</th>\n",
              "      <th>diag_3</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>max_glu_serum</th>\n",
              "      <th>A1Cresult</th>\n",
              "      <th>metformin</th>\n",
              "      <th>repaglinide</th>\n",
              "      <th>nateglinide</th>\n",
              "      <th>chlorpropamide</th>\n",
              "      <th>glimepiride</th>\n",
              "      <th>acetohexamide</th>\n",
              "      <th>glipizide</th>\n",
              "      <th>glyburide</th>\n",
              "      <th>tolbutamide</th>\n",
              "      <th>pioglitazone</th>\n",
              "      <th>rosiglitazone</th>\n",
              "      <th>acarbose</th>\n",
              "      <th>miglitol</th>\n",
              "      <th>troglitazone</th>\n",
              "      <th>tolazamide</th>\n",
              "      <th>examide</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.83</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.01</td>\n",
              "      <td>255.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>648.00</td>\n",
              "      <td>250.00</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>250.43</td>\n",
              "      <td>403.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>197.00</td>\n",
              "      <td>157.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65529</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>427.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>70.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65530</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>812.00</td>\n",
              "      <td>424.00</td>\n",
              "      <td>888.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65531</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>786.00</td>\n",
              "      <td>427.00</td>\n",
              "      <td>401.0</td>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65532</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>85</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>996.00</td>\n",
              "      <td>43.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65533</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.0</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65534 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  race  gender  age  ...  change  diabetesMed  readmitted\n",
              "0            Caucasian  Female    5  ...      No           No          NO\n",
              "1            Caucasian  Female   15  ...      Ch          Yes         >30\n",
              "2      AfricanAmerican  Female   25  ...      No          Yes          NO\n",
              "3            Caucasian    Male   35  ...      Ch          Yes          NO\n",
              "4            Caucasian    Male   45  ...      Ch          Yes          NO\n",
              "...                ...     ...  ...  ...     ...          ...         ...\n",
              "65529        Caucasian  Female   65  ...      Ch          Yes          NO\n",
              "65530        Caucasian  Female   75  ...      No          Yes          NO\n",
              "65531  AfricanAmerican  Female   75  ...      No           No          NO\n",
              "65532        Caucasian  Female   85  ...      No          Yes         >30\n",
              "65533        Caucasian    Male   55  ...      No           No          NO\n",
              "\n",
              "[65534 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSojTaAUX37N"
      },
      "source": [
        "Fill NA with the mean of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gQWl-T2ZNgz"
      },
      "source": [
        "#Fill Na with mean of the column\n",
        "#Diag 1\n",
        "df_modified['diag_1'] = df_modified['diag_1'].fillna(df_modified['diag_1'].mean())\n",
        "\n",
        "#diag_2\n",
        "df_modified['diag_2'] = df_modified['diag_2'].fillna(df_modified['diag_2'].mean())\n",
        "\n",
        "#diag_3\n",
        "df_modified['diag_3'] = df_modified['diag_3'].fillna(df_modified['diag_3'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVDpti5_TYpD"
      },
      "source": [
        "Prep data to be used for modeling \n",
        "Convert all strings to a int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XxloTlu_-HI"
      },
      "source": [
        "**Only run time **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "dB0DMUVLRTtD",
        "outputId": "f9c4b8c9-89e0-4b88-da60-5829654d6992"
      },
      "source": [
        "#converting strings to nums\n",
        "#Max glu serum\n",
        "df_modified['max_glu_serum'] = df_modified['max_glu_serum'].map({\n",
        "    '>200':int(0),\n",
        "    '>300':int(1),\n",
        "    'None':int(2),\n",
        "    'Norm':int(3), \n",
        "})\n",
        "#A1Cresult\n",
        "df_modified['A1Cresult'] = df_modified['A1Cresult'].map({\n",
        "    '7' :int(0),\n",
        "    'None' :int(1),\n",
        "    '8':int(2),\n",
        "    'Norm':int(3),\n",
        "})\n",
        "#metformin\n",
        "df_modified['metformin'] = df_modified['metformin'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3),\n",
        "})\n",
        "\n",
        "#repaglinide\n",
        "df_modified['repaglinide'] = df_modified['repaglinide'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3),\n",
        "})\n",
        "#nateglinide\n",
        "df_modified['nateglinide'] = df_modified['nateglinide'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3),\n",
        "})\n",
        "#Chlorpropamid\n",
        "df_modified['chlorpropamide'] = df_modified['chlorpropamide'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#Glimepiride\n",
        "df_modified['glimepiride'] = df_modified['glimepiride'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#acetohaxamide\n",
        "df_modified['acetohexamide'] = df_modified['acetohexamide'].map({\n",
        "    'No' :int(0),\n",
        "    'Steady' :int(1),\n",
        "})\n",
        "\n",
        "#glipizide\n",
        "df_modified['glipizide'] = df_modified['glipizide'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#glyburide\n",
        "df_modified['glyburide'] = df_modified['glyburide'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#tolbutamide\n",
        "df_modified['tolbutamide'] = df_modified['tolbutamide'].map({\n",
        "    'No' :int(0),\n",
        "    'Steady' :int(1),\n",
        "})\n",
        "#pioglitazone\n",
        "df_modified['pioglitazone'] = df_modified['pioglitazone'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#rosiglitazone\n",
        "df_modified['rosiglitazone'] = df_modified['rosiglitazone'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#acarbose\n",
        "df_modified['acarbose'] = df_modified['acarbose'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3) \n",
        "})\n",
        "#Miglitol\n",
        "df_modified['miglitol'] = df_modified['miglitol'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#troglitazone\n",
        "df_modified['troglitazone'] = df_modified['troglitazone'].map({\n",
        "    'No' :int(0),\n",
        "    'Steady' :int(1),\n",
        "})\n",
        "#tolazamide\n",
        "df_modified['tolazamide'] = df_modified['tolazamide'].map({\n",
        "    'No' :int(0),\n",
        "    'Steady' :int(1),\n",
        "    'Up' :int(2),\n",
        "})\n",
        "#examide\n",
        "df_modified['examide'] = df_modified['examide'].map({\n",
        "    'No' :int(0),\n",
        "})\n",
        "#citoglipton\n",
        "df_modified['citoglipton'] = df_modified['citoglipton'].map({\n",
        "    'No' :int(0),\n",
        "})\n",
        "#insulin\n",
        "df_modified['insulin'] = df_modified['insulin'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#glyburide-metformin\n",
        "df_modified['glyburide-metformin'] = df_modified['glyburide-metformin'].map({\n",
        "    'Down' :int(0),\n",
        "    'No' :int(1),\n",
        "    'Steady' :int(2),\n",
        "    'Up':int(3)\n",
        "})\n",
        "#glipizide-metformin\n",
        "df_modified['glipizide-metformin'] = df_modified['glipizide-metformin'].map({\n",
        "    'No' :int(0),\n",
        "    'Steady':int(1),\n",
        "})\n",
        "#glimepiride-pioglitazone\n",
        "df_modified['glimepiride-pioglitazone'] = df_modified['glimepiride-pioglitazone'].map({\n",
        "    'No' :int(0),\n",
        "})\n",
        "#Metformin-Rosiglitazone\n",
        "df_modified['metformin-rosiglitazone'] = df_modified['metformin-rosiglitazone'].map({\n",
        "    'No' :int(0),})\n",
        "#Metformin-pioglitazone\n",
        "df_modified['metformin-pioglitazone'] = df_modified['metformin-pioglitazone'].map({\n",
        "    'No' :int(0),})\n",
        "#Change\n",
        "df_modified['change'] = df_modified['change'].map({\n",
        "    'No' :int(0),\n",
        "    'Ch' :int(1),})\n",
        "#Diabetes Med\n",
        "df_modified['diabetesMed'] = df_modified['diabetesMed'].map({\n",
        "    'No' :int(0),\n",
        "    'Yes' :int(1),})\n",
        "#Readmitted\n",
        "df_modified['readmitted'] = df_modified['readmitted'].map({\n",
        "    'NO' :int(0),\n",
        "    '<30' :int(1),\n",
        "    '>30' :int(2),})\n",
        "df_modified"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_outpatient</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>diag_1</th>\n",
              "      <th>diag_2</th>\n",
              "      <th>diag_3</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>max_glu_serum</th>\n",
              "      <th>A1Cresult</th>\n",
              "      <th>metformin</th>\n",
              "      <th>repaglinide</th>\n",
              "      <th>nateglinide</th>\n",
              "      <th>chlorpropamide</th>\n",
              "      <th>glimepiride</th>\n",
              "      <th>acetohexamide</th>\n",
              "      <th>glipizide</th>\n",
              "      <th>glyburide</th>\n",
              "      <th>tolbutamide</th>\n",
              "      <th>pioglitazone</th>\n",
              "      <th>rosiglitazone</th>\n",
              "      <th>acarbose</th>\n",
              "      <th>miglitol</th>\n",
              "      <th>troglitazone</th>\n",
              "      <th>tolazamide</th>\n",
              "      <th>examide</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250.83</td>\n",
              "      <td>427.512086</td>\n",
              "      <td>402.913299</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>276.00</td>\n",
              "      <td>250.010000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>648.00</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>250.430000</td>\n",
              "      <td>403.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>197.00</td>\n",
              "      <td>157.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65529</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>427.00</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65530</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>812.00</td>\n",
              "      <td>424.000000</td>\n",
              "      <td>888.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65531</th>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>786.00</td>\n",
              "      <td>427.000000</td>\n",
              "      <td>401.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65532</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>85</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>996.00</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65533</th>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>55</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>276.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65534 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  race  gender  age  ...  change  diabetesMed  readmitted\n",
              "0            Caucasian  Female    5  ...       0            0           0\n",
              "1            Caucasian  Female   15  ...       1            1           2\n",
              "2      AfricanAmerican  Female   25  ...       0            1           0\n",
              "3            Caucasian    Male   35  ...       1            1           0\n",
              "4            Caucasian    Male   45  ...       1            1           0\n",
              "...                ...     ...  ...  ...     ...          ...         ...\n",
              "65529        Caucasian  Female   65  ...       1            1           0\n",
              "65530        Caucasian  Female   75  ...       0            1           0\n",
              "65531  AfricanAmerican  Female   75  ...       0            0           0\n",
              "65532        Caucasian  Female   85  ...       0            1           2\n",
              "65533        Caucasian    Male   55  ...       0            0           0\n",
              "\n",
              "[65534 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjPlOySwSz_r",
        "outputId": "20d7ad7e-6bd5-449d-ce0c-c8c7b7c4fd04"
      },
      "source": [
        "df_modified.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 65534 entries, 0 to 65533\n",
            "Data columns (total 45 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   race                      64201 non-null  object \n",
            " 1   gender                    65534 non-null  object \n",
            " 2   age                       65534 non-null  int64  \n",
            " 3   admission_type_id         65534 non-null  int64  \n",
            " 4   discharge_disposition_id  65534 non-null  int64  \n",
            " 5   admission_source_id       65534 non-null  int64  \n",
            " 6   time_in_hospital          65534 non-null  int64  \n",
            " 7   num_lab_procedures        65534 non-null  int64  \n",
            " 8   num_procedures            65534 non-null  int64  \n",
            " 9   num_medications           65534 non-null  int64  \n",
            " 10  number_outpatient         65534 non-null  int64  \n",
            " 11  number_emergency          65534 non-null  int64  \n",
            " 12  number_inpatient          65534 non-null  int64  \n",
            " 13  diag_1                    65534 non-null  float64\n",
            " 14  diag_2                    65534 non-null  float64\n",
            " 15  diag_3                    65534 non-null  float64\n",
            " 16  number_diagnoses          65534 non-null  int64  \n",
            " 17  max_glu_serum             65534 non-null  int64  \n",
            " 18  A1Cresult                 65534 non-null  int64  \n",
            " 19  metformin                 65534 non-null  int64  \n",
            " 20  repaglinide               65534 non-null  int64  \n",
            " 21  nateglinide               65534 non-null  int64  \n",
            " 22  chlorpropamide            65534 non-null  int64  \n",
            " 23  glimepiride               65534 non-null  int64  \n",
            " 24  acetohexamide             65534 non-null  int64  \n",
            " 25  glipizide                 65534 non-null  int64  \n",
            " 26  glyburide                 65534 non-null  int64  \n",
            " 27  tolbutamide               65534 non-null  int64  \n",
            " 28  pioglitazone              65534 non-null  int64  \n",
            " 29  rosiglitazone             65534 non-null  int64  \n",
            " 30  acarbose                  65534 non-null  int64  \n",
            " 31  miglitol                  65534 non-null  int64  \n",
            " 32  troglitazone              65534 non-null  int64  \n",
            " 33  tolazamide                65534 non-null  int64  \n",
            " 34  examide                   65534 non-null  int64  \n",
            " 35  citoglipton               65534 non-null  int64  \n",
            " 36  insulin                   65534 non-null  int64  \n",
            " 37  glyburide-metformin       65534 non-null  int64  \n",
            " 38  glipizide-metformin       65534 non-null  int64  \n",
            " 39  glimepiride-pioglitazone  65534 non-null  int64  \n",
            " 40  metformin-rosiglitazone   65534 non-null  int64  \n",
            " 41  metformin-pioglitazone    65534 non-null  int64  \n",
            " 42  change                    65534 non-null  int64  \n",
            " 43  diabetesMed               65534 non-null  int64  \n",
            " 44  readmitted                65534 non-null  int64  \n",
            "dtypes: float64(3), int64(40), object(2)\n",
            "memory usage: 22.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAM_6PFpTnPO"
      },
      "source": [
        "Convert floats to int\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihGAV2jWTq6q"
      },
      "source": [
        "floatVar = [ 'diag_1', 'diag_2','diag_3']\n",
        "for var in floatVar:\n",
        "  df_modified[var] = df_modified[var].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFAKlFBBS4cU"
      },
      "source": [
        "df_modified = df_modified.select_dtypes(include='int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrPEo7iWrJ4V"
      },
      "source": [
        "# Separate the dataset by A1C results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0tDh6tuP-IE"
      },
      "source": [
        "None = df_None\n",
        "\n",
        "Norm = df_Norm\n",
        "\n",
        "7 = df_7\n",
        "\n",
        "8 = df_8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpF6kxzEuTQz"
      },
      "source": [
        "#Split the dataframe by groups \n",
        "AC1group = df_modified.groupby(df_modified.A1Cresult)\n",
        "df_None = AC1group.get_group(1)\n",
        "df_Norm = AC1group.get_group(3)\n",
        "df_7 = AC1group.get_group(0)\n",
        "df_8 =AC1group.get_group(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_6_sh5kddca",
        "outputId": "14e13bb7-0273-449e-d4f6-3d8219ec36bc"
      },
      "source": [
        "df_modified.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'admission_type_id', 'discharge_disposition_id',\n",
              "       'admission_source_id', 'time_in_hospital', 'num_lab_procedures',\n",
              "       'num_procedures', 'num_medications', 'number_outpatient',\n",
              "       'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3',\n",
              "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
              "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
              "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
              "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
              "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
              "       'glyburide-metformin', 'glipizide-metformin',\n",
              "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
              "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htxbk9zQrC7B"
      },
      "source": [
        "# Correlation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISIv8K3xVqi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb7e757-ee77-48de-bedb-07929c8d9319"
      },
      "source": [
        "#create a list of variables to use for the correlation test\n",
        "drugs = df_modified.columns[15:44]\n",
        "drugs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide',\n",
              "       'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide',\n",
              "       'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
              "       'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton',\n",
              "       'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
              "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
              "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCR3MN3iOnN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10f7d52-765d-40fe-8fbe-391273cd37b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "#function to find the Correlation Coefficient\n",
        "def corTest(a:pd.Series , var1):\n",
        "  column_1 = a['readmitted']\n",
        "  column_2 = a[var1]\n",
        "  print(var1)\n",
        "  correlationP = column_1.corr(column_2,method = 'pearson')\n",
        "  print('Pearson:',correlationP)\n",
        "  correlationK = column_1.corr(column_2,method = 'kendall')\n",
        "  print('Kendall:',correlationK)\n",
        "  correlationS = column_1.corr(column_2,method = 'spearman')\n",
        "  print('Spearman:',correlationS)\n",
        "  highest = max(correlationK , correlationP, correlationS)\n",
        "  return var1, highest\n",
        "\n",
        "#Loop to feed list into function\n",
        "#create a list of drug and it's highest correlation coeffiecent\n",
        "#Step 1 Create List to store the correlation\n",
        "#Step 2 check if value is nan\n",
        "#Step 3 Add to List if not nan\n",
        "highCorr = {}\n",
        "for drug in drugs:\n",
        "  corTest(df_modified,drug)\n",
        "  highDrug = corTest(df_modified,drug)\n",
        "  nanCheck = math.isnan(highDrug[1])\n",
        "  if nanCheck == False:\n",
        "    highCorr[highDrug[0]] = highDrug[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_glu_serum\n",
            "Pearson: -0.008644799663187397\n",
            "Kendall: -0.010378962695385869\n",
            "Spearman: -0.010913864772288019\n",
            "max_glu_serum\n",
            "Pearson: -0.008644799663187397\n",
            "Kendall: -0.010378962695385869\n",
            "Spearman: -0.010913864772288019\n",
            "A1Cresult\n",
            "Pearson: -0.010844623862441479\n",
            "Kendall: -0.008851628248041607\n",
            "Spearman: -0.009419323117442271\n",
            "A1Cresult\n",
            "Pearson: -0.010844623862441479\n",
            "Kendall: -0.008851628248041607\n",
            "Spearman: -0.009419323117442271\n",
            "metformin\n",
            "Pearson: -0.017498229303004688\n",
            "Kendall: -0.017699152887729722\n",
            "Spearman: -0.018484820830357986\n",
            "metformin\n",
            "Pearson: -0.017498229303004688\n",
            "Kendall: -0.017699152887729722\n",
            "Spearman: -0.018484820830357986\n",
            "repaglinide\n",
            "Pearson: 0.018327414359143732\n",
            "Kendall: 0.02168512422236489\n",
            "Spearman: 0.022549886677802042\n",
            "repaglinide\n",
            "Pearson: 0.018327414359143732\n",
            "Kendall: 0.02168512422236489\n",
            "Spearman: 0.022549886677802042\n",
            "nateglinide\n",
            "Pearson: 0.009847839297555077\n",
            "Kendall: 0.010431098758690143\n",
            "Spearman: 0.010841734961582382\n",
            "nateglinide\n",
            "Pearson: 0.009847839297555077\n",
            "Kendall: 0.010431098758690143\n",
            "Spearman: 0.010841734961582382\n",
            "chlorpropamide\n",
            "Pearson: 0.00414478517986786\n",
            "Kendall: 0.0016981853281506695\n",
            "Spearman: 0.0017651306934305657\n",
            "chlorpropamide\n",
            "Pearson: 0.00414478517986786\n",
            "Kendall: 0.0016981853281506695\n",
            "Spearman: 0.0017651306934305657\n",
            "glimepiride\n",
            "Pearson: 0.009037204892088794\n",
            "Kendall: 0.01098726432540433\n",
            "Spearman: 0.011446790539672468\n",
            "glimepiride\n",
            "Pearson: 0.009037204892088794\n",
            "Kendall: 0.01098726432540433\n",
            "Spearman: 0.011446790539672468\n",
            "acetohexamide\n",
            "Pearson: 0.0049385090563733225\n",
            "Kendall: 0.004658623954347239\n",
            "Spearman: 0.004841675854171218\n",
            "acetohexamide\n",
            "Pearson: 0.0049385090563733225\n",
            "Kendall: 0.004658623954347239\n",
            "Spearman: 0.004841675854171218\n",
            "glipizide\n",
            "Pearson: 0.013389078018969856\n",
            "Kendall: 0.013138368025264958\n",
            "Spearman: 0.013749960303725805\n",
            "glipizide\n",
            "Pearson: 0.013389078018969856\n",
            "Kendall: 0.013138368025264958\n",
            "Spearman: 0.013749960303725805\n",
            "glyburide\n",
            "Pearson: -0.011715993787880278\n",
            "Kendall: -0.011748966081282973\n",
            "Spearman: -0.012294934954787687\n",
            "glyburide\n",
            "Pearson: -0.011715993787880278\n",
            "Kendall: -0.011748966081282973\n",
            "Spearman: -0.012294934954787687\n",
            "tolbutamide\n",
            "Pearson: -0.004608689211692383\n",
            "Kendall: -0.0045778645832618\n",
            "Spearman: -0.004757743194910848\n",
            "tolbutamide\n",
            "Pearson: -0.004608689211692383\n",
            "Kendall: -0.0045778645832618\n",
            "Spearman: -0.004757743194910848\n",
            "pioglitazone\n",
            "Pearson: 0.023415238830669045\n",
            "Kendall: 0.02201103889110334\n",
            "Spearman: 0.02291858485241997\n",
            "pioglitazone\n",
            "Pearson: 0.023415238830669045\n",
            "Kendall: 0.02201103889110334\n",
            "Spearman: 0.02291858485241997\n",
            "rosiglitazone\n",
            "Pearson: 0.012652745089055584\n",
            "Kendall: 0.013476301030993112\n",
            "Spearman: 0.014024166399854982\n",
            "rosiglitazone\n",
            "Pearson: 0.012652745089055584\n",
            "Kendall: 0.013476301030993112\n",
            "Spearman: 0.014024166399854982\n",
            "acarbose\n",
            "Pearson: 0.010873601556787692\n",
            "Kendall: 0.009848937968659696\n",
            "Spearman: 0.010237074373499732\n",
            "acarbose\n",
            "Pearson: 0.010873601556787692\n",
            "Kendall: 0.009848937968659696\n",
            "Spearman: 0.010237074373499732\n",
            "miglitol\n",
            "Pearson: 0.0035045720239296934\n",
            "Kendall: 0.0024302929220704986\n",
            "Spearman: 0.002525866853345767\n",
            "miglitol\n",
            "Pearson: 0.0035045720239296934\n",
            "Kendall: 0.0024302929220704986\n",
            "Spearman: 0.002525866853345767\n",
            "troglitazone\n",
            "Pearson: 0.0036819212035160065\n",
            "Kendall: 0.003403862457490889\n",
            "Spearman: 0.0035376108552343448\n",
            "troglitazone\n",
            "Pearson: 0.0036819212035160065\n",
            "Kendall: 0.003403862457490889\n",
            "Spearman: 0.0035376108552343448\n",
            "tolazamide\n",
            "Pearson: -0.005327173843955536\n",
            "Kendall: -0.00619282574961222\n",
            "Spearman: -0.006436183799819743\n",
            "tolazamide\n",
            "Pearson: -0.005327173843955536\n",
            "Kendall: -0.00619282574961222\n",
            "Spearman: -0.006436183799819743\n",
            "examide\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "examide\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "citoglipton\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "citoglipton\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "insulin\n",
            "Pearson: 0.0039425247336816426\n",
            "Kendall: 0.0020242425541733074\n",
            "Spearman: 0.0021821209193396466\n",
            "insulin\n",
            "Pearson: 0.0039425247336816426\n",
            "Kendall: 0.0020242425541733074\n",
            "Spearman: 0.0021821209193396466\n",
            "glyburide-metformin\n",
            "Pearson: 0.007287287646330169\n",
            "Kendall: 0.008057855914312715\n",
            "Spearman: 0.008375265223693341\n",
            "glyburide-metformin\n",
            "Pearson: 0.007287287646330169\n",
            "Kendall: 0.008057855914312715\n",
            "Spearman: 0.008375265223693341\n",
            "glipizide-metformin\n",
            "Pearson: 0.003609202302207248\n",
            "Kendall: 0.003429209505964073\n",
            "Spearman: 0.0035639538684867026\n",
            "glipizide-metformin\n",
            "Pearson: 0.003609202302207248\n",
            "Kendall: 0.003429209505964073\n",
            "Spearman: 0.0035639538684867026\n",
            "glimepiride-pioglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "glimepiride-pioglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "metformin-rosiglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "metformin-rosiglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "metformin-pioglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "metformin-pioglitazone\n",
            "Pearson: nan\n",
            "Kendall: nan\n",
            "Spearman: nan\n",
            "change\n",
            "Pearson: 0.04289315825686413\n",
            "Kendall: 0.04211915536703473\n",
            "Spearman: 0.04377414866215192\n",
            "change\n",
            "Pearson: 0.04289315825686413\n",
            "Kendall: 0.04211915536703473\n",
            "Spearman: 0.04377414866215192\n",
            "diabetesMed\n",
            "Pearson: 0.05847950023954672\n",
            "Kendall: 0.05758035648571211\n",
            "Spearman: 0.05984286871046807\n",
            "diabetesMed\n",
            "Pearson: 0.05847950023954672\n",
            "Kendall: 0.05758035648571211\n",
            "Spearman: 0.05984286871046807\n",
            "readmitted\n",
            "Pearson: 0.9999999999999999\n",
            "Kendall: 1.0\n",
            "Spearman: 1.0\n",
            "readmitted\n",
            "Pearson: 0.9999999999999999\n",
            "Kendall: 1.0\n",
            "Spearman: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgy4nxOcyPys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e414f9af-3949-4fe9-b811-2666f6716cc1"
      },
      "source": [
        "#Look at dictionary and find the top 2 highest neg and highest pos\n",
        "highCorr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A1Cresult': -0.008851628248041607,\n",
              " 'acarbose': 0.010873601556787692,\n",
              " 'acetohexamide': 0.0049385090563733225,\n",
              " 'change': 0.04377414866215192,\n",
              " 'chlorpropamide': 0.00414478517986786,\n",
              " 'diabetesMed': 0.05984286871046807,\n",
              " 'glimepiride': 0.011446790539672468,\n",
              " 'glipizide': 0.013749960303725805,\n",
              " 'glipizide-metformin': 0.003609202302207248,\n",
              " 'glyburide': -0.011715993787880278,\n",
              " 'glyburide-metformin': 0.008375265223693341,\n",
              " 'insulin': 0.0039425247336816426,\n",
              " 'max_glu_serum': -0.008644799663187397,\n",
              " 'metformin': -0.017498229303004688,\n",
              " 'miglitol': 0.0035045720239296934,\n",
              " 'nateglinide': 0.010841734961582382,\n",
              " 'pioglitazone': 0.023415238830669045,\n",
              " 'readmitted': 1.0,\n",
              " 'repaglinide': 0.022549886677802042,\n",
              " 'rosiglitazone': 0.014024166399854982,\n",
              " 'tolazamide': -0.005327173843955536,\n",
              " 'tolbutamide': -0.0045778645832618,\n",
              " 'troglitazone': 0.0036819212035160065}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJEgDT0e5W2s"
      },
      "source": [
        "#'glyburide': -0.011715993787880278\n",
        "#'metformin': -0.017498229303004688\n",
        "highNeg = ['glyburide', 'metformin']\n",
        "#'diabetesMed': 0.05984286871046807\n",
        "#'change': 0.04377414866215192\n",
        "highPos = ['diabetesMed', 'change']\n",
        "\n",
        "#Function to calculate the r2/correlation of the three variables based on A1C results to readmittance rate\n",
        "def multipleCorr(var1 , a:pd.Series):\n",
        "  cor = a.corr()\n",
        "  xz = cor.loc[var1[0],'readmitted']\n",
        "  yz = cor.loc[var1[1],'readmitted']\n",
        "  xy = cor.loc[var1[0],var1[1]]\n",
        "  Rxyz = math.sqrt((abs(xz**2) + abs(yz**2) - 2*xz*yz*xy) / (1-abs(xy**2)) )\n",
        "  R2 = Rxyz**2\n",
        "\n",
        "  n = len(a)\n",
        "  k= 2\n",
        "  R2_adj = 1 - ( ((1-R2)*(n-1)) / (n-k-1) )\n",
        "  return R2\n",
        "\n",
        "print('The top two highest correlation for increasing readdmission')\n",
        "print(multipleCorr(highPos, df_modified))\n",
        "print(multipleCorr(highPos, df_Norm))\n",
        "print(multipleCorr(highPos, df_7))\n",
        "print(multipleCorr(highPos, df_8))\n",
        "\n",
        "print('The top two highest correlation for decreasing readdmission')\n",
        "print(multipleCorr(highNeg, df_modified))\n",
        "print(multipleCorr(highNeg, df_Norm))\n",
        "print(multipleCorr(highNeg, df_7))\n",
        "print(multipleCorr(highNeg, df_8))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIxGJKMBqJu"
      },
      "source": [
        "# Prep for model analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64W7Bpfmq01e"
      },
      "source": [
        "## Splitting the datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKvWv_9kCzb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#function to split the data set\n",
        "def splitX(a:pd.Series, var1):\n",
        "  x = a.drop([var1], axis = 1)\n",
        "  return x\n",
        "\n",
        "def splitY(a:pd.Series, var1):\n",
        "    y = a.pop(var1)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BSEF-n8kLnF"
      },
      "source": [
        "#split the datasets\n",
        "#Modified\n",
        "xMod = splitX(df_modified,'readmitted')\n",
        "yMod = splitX(df_modified,'readmitted')\n",
        "\n",
        "#A1C result None\n",
        "xNone = splitX(df_None,'readmitted')\n",
        "yNone = splitY(df_None,'readmitted')\n",
        "\n",
        "#A1C result Norm\n",
        "xNorm = splitX(df_Norm,'readmitted')\n",
        "yNorm = splitY(df_Norm,'readmitted')\n",
        "\n",
        "#A1C result 7\n",
        "x7 = splitX(df_7,'readmitted')\n",
        "y7 = splitY(df_7,'readmitted')\n",
        "\n",
        "#A1C result 8\n",
        "x8 = splitX(df_8,'readmitted')\n",
        "y8 = splitY(df_8,'readmitted')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNCjCk1szAtI"
      },
      "source": [
        "## Function to show results \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGtCG6gv0sje"
      },
      "source": [
        "def showRes(scores):\n",
        "  print('Accuracy on Train set',scores[0])\n",
        "  print('Accuracy on Test set',scores[1])\n",
        "  print('F1-score on Test set:',scores[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUGiEz_mqv0T"
      },
      "source": [
        "# Navie Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQvtHG99OY9s"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Navie Bayes function\n",
        "def navieBayes(xtrain, xtest, ytest, ytrain):\n",
        "  sc = StandardScaler()\n",
        "  xtrain = sc.fit_transform(xtrain)\n",
        "  xtest = sc.transform(xtest)\n",
        "  NB_model = GaussianNB()\n",
        "  # fit the model\n",
        "  NB_model.fit(xtrain, ytrain)\n",
        "\n",
        "  y_predict_NB = NB_model.predict(xtest)\n",
        "\n",
        "  # model score\n",
        "  predict_train_NB = NB_model.predict(xtrain)\n",
        "  predict_test_NB = NB_model.predict(xtest)\n",
        "\n",
        "  # accuracy score\n",
        "  NB_train_score = NB_model.score(xtrain,ytrain)\n",
        "  NB_test_score = NB_model.score(xtest,ytest)\n",
        "\n",
        "  # f1-score\n",
        "  NB_f1_score = metrics.f1_score(ytest,predict_test_NB, average='micro')\n",
        "  NB_recall = metrics.recall_score(ytest, predict_test_NB, average='micro')\n",
        "\n",
        "  print(metrics.classification_report(y_test, predict_test_NB))\n",
        "  return NB_train_score, NB_test_score, NB_f1_score, NB_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYgT-g0Kqp0u"
      },
      "source": [
        "# Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSTqhd7sidMt"
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "#LDA function\n",
        "def LDA(xtrain, xtest, ytest, ytrain):\n",
        "  LDA = LinearDiscriminantAnalysis(solver='svd')\n",
        "  # fit the model\n",
        "  LDA.fit(xtrain, ytrain)\n",
        "\n",
        "  y_predict_LDA = LDA.predict(xtest)\n",
        "\n",
        "  # model score\n",
        "  predict_train_LDA = LDA.predict(xtrain)\n",
        "  predict_test_LDA = LDA.predict(xtest)\n",
        "\n",
        "  # accuracy score\n",
        "  LDA_train_score = LDA.score(xtrain,ytrain)\n",
        "  LDA_test_score = LDA.score(xtest,ytest)\n",
        "\n",
        "  # f1-score\n",
        "  LDA_f1_score = metrics.f1_score(ytest,predict_test_LDA, average ='weighted')\n",
        "  LDA_recall = metrics.recall_score(ytest, predict_test_LDA, average = 'weighted')\n",
        "\n",
        "  print(metrics.classification_report(ytest, predict_test_LDA))\n",
        "  return LDA_train_score, LDA_test_score, LDA_f1_score, LDA_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9prpKaL1qllx"
      },
      "source": [
        "# Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF2iQYpblXci"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "#Logistic Regression Function\n",
        "def logReg(xtrain, xtest, ytest, ytrain):\n",
        "  LR_model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "  # fit the model\n",
        "  LR_model.fit(xtrain, ytrain)\n",
        "\n",
        "  y_predict_LR = LR_model.predict(xtest)\n",
        "\n",
        "  # model score\n",
        "  predict_train_LR = LR_model.predict(xtrain)\n",
        "  predict_test_LR = LR_model.predict(xtest)\n",
        "\n",
        "  # accuracy score\n",
        "  LR_train_score = LR_model.score(xtrain,ytrain)\n",
        "  LR_test_score = LR_model.score(xtest,ytest)\n",
        "\n",
        "  # f1-score\n",
        "  LR_f1_score = metrics.f1_score(ytest,predict_test_LR, average= 'micro')\n",
        "  LR_recall = metrics.recall_score(ytest,predict_test_LR, average = 'micro')\n",
        "\n",
        "  print(metrics.classification_report(ytest, predict_test_LR))\n",
        "  return LR_train_score, LR_test_score, LR_f1_score, LR_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRU1eA2yqe3N"
      },
      "source": [
        "# Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--uVq12MnWss"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "def decTree(xtrain, xtest, ytest, ytrain):\n",
        "  DT_model= DecisionTreeClassifier()\n",
        "\n",
        "  # fit the model\n",
        "  DT_model.fit(xtrain,ytrain)\n",
        "\n",
        "  # model score\n",
        "  predict_train_DT = DT_model.predict(xtrain)\n",
        "  predict_test_DT = DT_model.predict(xtest)\n",
        "\n",
        "  # accuracy score\n",
        "  DT_train_score = DT_model.score(xtrain,ytrain)\n",
        "  DT_test_score = DT_model.score(xtest,ytest)\n",
        "\n",
        "  # f1-score\n",
        "  DT_f1_score = metrics.f1_score(ytest, predict_test_DT, average = 'weighted')\n",
        "  DT_recall = metrics.recall_score(ytest, predict_test_DT, average = 'weighted')\n",
        "  \n",
        "  print(metrics.classification_report(ytest, predict_test_DT))\n",
        "  return DT_train_score, DT_test_score, DT_f1_score, DT_recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbNIKck0qXux"
      },
      "source": [
        "#Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcufiTWaozJu"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def ranFor(xtrain, xtest, ytest, ytrain):\n",
        "  # create object model\n",
        "  RF_model = RandomForestClassifier()\n",
        "\n",
        "  # fit the model\n",
        "  RF_model.fit(xtrain,ytrain)\n",
        "\n",
        "  # model score\n",
        "  predict_train_RF = RF_model.predict(xtrain)\n",
        "  predict_test_RF = RF_model.predict(xtest)\n",
        "\n",
        "  # accuracy score\n",
        "  RF_train_score = RF_model.score(xtrain,ytrain)\n",
        "  RF_test_score = RF_model.score(xtest,ytest)\n",
        "\n",
        "  # f1-score\n",
        "  RF_f1_score = metrics.f1_score(ytest,predict_test_RF, average = 'micro')\n",
        "  RF_recall = metrics.recall_score(ytest,predict_test_RF, average ='micro')\n",
        "\n",
        "  print(metrics.classification_report(ytest,predict_test_RF))\n",
        "  return RF_train_score, RF_test_score, RF_f1_score, RF_recall\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjzLsfcrwXJ"
      },
      "source": [
        "# Navie Bayes Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBYSC_SLeSOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497c7a31-daff-493f-ea99-ac8be57d804d"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "showRes(NBscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00      8709\n",
            "           1       0.12      1.00      0.21      1966\n",
            "           2       0.43      0.00      0.00      5967\n",
            "\n",
            "    accuracy                           0.12     16642\n",
            "   macro avg       0.40      0.33      0.07     16642\n",
            "weighted avg       0.52      0.12      0.03     16642\n",
            "\n",
            "Accuracy on Train set 0.11689114367386881\n",
            "Accuracy on Test set 0.11945679605816609\n",
            "F1-score on Test set: 0.11945679605816609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV-S_7J0eenB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8781d1a5-b300-468f-9c28-c1092779fbb5"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "NBscore =navieBayes(x_train, x_test, y_test, y_train)\n",
        "showRes(NBscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.01      0.02       445\n",
            "           1       0.10      0.93      0.19        88\n",
            "           2       0.33      0.01      0.03       284\n",
            "\n",
            "    accuracy                           0.11       817\n",
            "   macro avg       0.30      0.32      0.08       817\n",
            "weighted avg       0.37      0.11      0.04       817\n",
            "\n",
            "Accuracy on Train set 0.10661764705882353\n",
            "Accuracy on Test set 0.11138310893512852\n",
            "F1-score on Test set: 0.11138310893512852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg67H-oEendf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1c596e-b8ab-4197-f6de-ca8475e4cf2e"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "showRes(NBscore)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.00      0.01       334\n",
            "           1       0.11      0.99      0.20        69\n",
            "           2       0.38      0.01      0.03       221\n",
            "\n",
            "    accuracy                           0.12       624\n",
            "   macro avg       0.25      0.33      0.08       624\n",
            "weighted avg       0.28      0.12      0.03       624\n",
            "\n",
            "Accuracy on Train set 0.11493461803165864\n",
            "Accuracy on Test set 0.11538461538461539\n",
            "F1-score on Test set: 0.11538461538461539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wCFVVvNeuZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426065ee-01a8-40a7-c570-4d09cff43d14"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "showRes(NBscore)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       870\n",
            "           1       0.10      0.98      0.18       162\n",
            "           2       0.48      0.02      0.04       547\n",
            "\n",
            "    accuracy                           0.11      1579\n",
            "   macro avg       0.19      0.33      0.07      1579\n",
            "weighted avg       0.18      0.11      0.03      1579\n",
            "\n",
            "Accuracy on Train set 0.10640608034744843\n",
            "Accuracy on Test set 0.10639645345155162\n",
            "F1-score on Test set: 0.10639645345155162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Xl24zj9Ava"
      },
      "source": [
        "# Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iALiCtuE9GGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d29a5b5-fd67-4a24-e132-1e9d46d7a9f5"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "showRes(LDAscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.89      0.69      8709\n",
            "           1       0.37      0.05      0.09      1966\n",
            "           2       0.49      0.23      0.31      5967\n",
            "\n",
            "    accuracy                           0.55     16642\n",
            "   macro avg       0.48      0.39      0.36     16642\n",
            "weighted avg       0.52      0.55      0.48     16642\n",
            "\n",
            "Accuracy on Train set 0.5536555844557184\n",
            "Accuracy on Test set 0.5508352361495013\n",
            "F1-score on Test set: 0.48347036041535113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVyErEHu9U9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bebecd5-6e81-4c10-c7c7-fc9bbd3f297c"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "LDAscore =LDA(x_train, x_test, y_test, y_train)\n",
        "showRes(LDAscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.90      0.70       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.42      0.17      0.24       284\n",
            "\n",
            "    accuracy                           0.55       817\n",
            "   macro avg       0.33      0.36      0.31       817\n",
            "weighted avg       0.46      0.55      0.46       817\n",
            "\n",
            "Accuracy on Train set 0.601890756302521\n",
            "Accuracy on Test set 0.5483476132190942\n",
            "F1-score on Test set: 0.4647384623642904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Ptgxj69Z9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4947e0db-1baf-4319-ff32-66de162d86db"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "showRes(LDAscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.85      0.68       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.44      0.24      0.31       221\n",
            "\n",
            "    accuracy                           0.54       624\n",
            "   macro avg       0.33      0.36      0.33       624\n",
            "weighted avg       0.46      0.54      0.48       624\n",
            "\n",
            "Accuracy on Train set 0.5980729525120441\n",
            "Accuracy on Test set 0.5400641025641025\n",
            "F1-score on Test set: 0.475436506499134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuMIuCp39egJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65d1d48-639a-460c-907c-2a3530601444"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "showRes(LDAscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.84      0.71       870\n",
            "           1       0.17      0.02      0.03       162\n",
            "           2       0.50      0.34      0.41       547\n",
            "\n",
            "    accuracy                           0.58      1579\n",
            "   macro avg       0.43      0.40      0.38      1579\n",
            "weighted avg       0.53      0.58      0.54      1579\n",
            "\n",
            "Accuracy on Train set 0.5958197611292074\n",
            "Accuracy on Test set 0.5826472450918303\n",
            "F1-score on Test set: 0.5351660325626769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jnxpfzo9jfc"
      },
      "source": [
        "# Logistic Regression Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzxIT93D9r1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8faf259e-6231-43b2-e5da-911dadebf0f2"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "showRes(LRscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.87      0.69      8709\n",
            "           1       0.38      0.01      0.03      1966\n",
            "           2       0.48      0.26      0.34      5967\n",
            "\n",
            "    accuracy                           0.55     16642\n",
            "   macro avg       0.48      0.38      0.35     16642\n",
            "weighted avg       0.51      0.55      0.48     16642\n",
            "\n",
            "Accuracy on Train set 0.5574412196440988\n",
            "Accuracy on Test set 0.551195769739214\n",
            "F1-score on Test set: 0.551195769739214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI3VCz7b99DU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa9c6f4-017f-490c-a73a-2067400981f7"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "LRscore =logReg(x_train, x_test, y_test, y_train)\n",
        "showRes(LRscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.90      0.70       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.48      0.21      0.29       284\n",
            "\n",
            "    accuracy                           0.56       817\n",
            "   macro avg       0.35      0.37      0.33       817\n",
            "weighted avg       0.48      0.56      0.48       817\n",
            "\n",
            "Accuracy on Train set 0.6034663865546218\n",
            "Accuracy on Test set 0.5605875152998776\n",
            "F1-score on Test set: 0.5605875152998776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbq3yb6G9_bY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4241f02-200b-4a24-d204-766c8866b379"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "showRes(LRscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.84      0.68       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.46      0.28      0.34       221\n",
            "\n",
            "    accuracy                           0.55       624\n",
            "   macro avg       0.34      0.37      0.34       624\n",
            "weighted avg       0.47      0.55      0.49       624\n",
            "\n",
            "Accuracy on Train set 0.5960082587749483\n",
            "Accuracy on Test set 0.5464743589743589\n",
            "F1-score on Test set: 0.5464743589743589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzFCVXgO-DVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73320838-2a99-44f4-b298-bc7b376e6105"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "showRes(LRscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.86      0.72       870\n",
            "           1       0.25      0.01      0.01       162\n",
            "           2       0.52      0.35      0.42       547\n",
            "\n",
            "    accuracy                           0.60      1579\n",
            "   macro avg       0.46      0.41      0.38      1579\n",
            "weighted avg       0.55      0.60      0.54      1579\n",
            "\n",
            "Accuracy on Train set 0.6034201954397395\n",
            "Accuracy on Test set 0.5959468017732742\n",
            "F1-score on Test set: 0.5959468017732742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op-0NFA6-PU4"
      },
      "source": [
        "# Decision Tree Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4hBy6-1-W62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca90a56a-0e1b-45b7-fd10-2a0bec77f909"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "showRes(DTscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.57      0.57      8709\n",
            "           1       0.15      0.15      0.15      1966\n",
            "           2       0.41      0.42      0.42      5967\n",
            "\n",
            "    accuracy                           0.47     16642\n",
            "   macro avg       0.38      0.38      0.38     16642\n",
            "weighted avg       0.47      0.47      0.47     16642\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.4659295757721428\n",
            "F1-score on Test set: 0.4670413727278232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4BKsuQx-a1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708fd9ad-ddf7-4a8d-f91c-eefbd55235ff"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "showRes(DTscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.59      0.59       445\n",
            "           1       0.14      0.14      0.14        88\n",
            "           2       0.39      0.39      0.39       284\n",
            "\n",
            "    accuracy                           0.47       817\n",
            "   macro avg       0.37      0.37      0.37       817\n",
            "weighted avg       0.47      0.47      0.47       817\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.4700122399020808\n",
            "F1-score on Test set: 0.469893314446558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OoFRNaD-fOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6cefea-a17e-4160-b8bf-5255c4a1db23"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "showRes(DTscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57       334\n",
            "           1       0.11      0.12      0.11        69\n",
            "           2       0.37      0.40      0.39       221\n",
            "\n",
            "    accuracy                           0.45       624\n",
            "   macro avg       0.36      0.36      0.36       624\n",
            "weighted avg       0.46      0.45      0.46       624\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.4519230769230769\n",
            "F1-score on Test set: 0.4556920117364626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-lpY11f-jIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b36801-e980-4408-da52-ed64221485ca"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "showRes(DTscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.60      0.62       870\n",
            "           1       0.16      0.16      0.16       162\n",
            "           2       0.42      0.45      0.44       547\n",
            "\n",
            "    accuracy                           0.51      1579\n",
            "   macro avg       0.40      0.41      0.40      1579\n",
            "weighted avg       0.51      0.51      0.51      1579\n",
            "\n",
            "Accuracy on Train set 0.999728555917481\n",
            "Accuracy on Test set 0.5053831538948702\n",
            "F1-score on Test set: 0.5079884955516608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFGIiWy--TbB"
      },
      "source": [
        "# Random Forest Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpwKHS2d-pUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3880e138-0662-475c-85b4-537902911420"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "showRes(RFscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.80      0.69      8709\n",
            "           1       0.40      0.01      0.02      1966\n",
            "           2       0.49      0.41      0.44      5967\n",
            "\n",
            "    accuracy                           0.57     16642\n",
            "   macro avg       0.50      0.41      0.38     16642\n",
            "weighted avg       0.54      0.57      0.52     16642\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.5666386251652445\n",
            "F1-score on Test set: 0.5666386251652445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imyfsvT_-vFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f92f208-d182-400e-98b1-929d17a541ce"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "showRes(RFscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.88      0.70       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.47      0.23      0.31       284\n",
            "\n",
            "    accuracy                           0.56       817\n",
            "   macro avg       0.35      0.37      0.34       817\n",
            "weighted avg       0.48      0.56      0.49       817\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.5605875152998776\n",
            "F1-score on Test set: 0.5605875152998776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cJJLcNH-zbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fa59d8-1c35-4868-d344-9a41fb89e67b"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "showRes(RFscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.84      0.69       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.45      0.30      0.36       221\n",
            "\n",
            "    accuracy                           0.56       624\n",
            "   macro avg       0.35      0.38      0.35       624\n",
            "weighted avg       0.48      0.56      0.50       624\n",
            "\n",
            "Accuracy on Train set 1.0\n",
            "Accuracy on Test set 0.5560897435897436\n",
            "F1-score on Test set: 0.5560897435897436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03PsByfd-3iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f39d1ea-59ed-442b-b12b-b17c51cdbbb7"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "showRes(RFscore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.81      0.71       870\n",
            "           1       0.00      0.00      0.00       162\n",
            "           2       0.48      0.41      0.45       547\n",
            "\n",
            "    accuracy                           0.59      1579\n",
            "   macro avg       0.37      0.41      0.39      1579\n",
            "weighted avg       0.52      0.59      0.55      1579\n",
            "\n",
            "Accuracy on Train set 0.999728555917481\n",
            "Accuracy on Test set 0.5889803673210893\n",
            "F1-score on Test set: 0.5889803673210893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCxleDgS_CpY"
      },
      "source": [
        "# Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFbgpvz38CP"
      },
      "source": [
        " def modelCom(DTscore, RFscore, LRscore, LDAscore, NBscore): \n",
        "  model_compare = pd.DataFrame({\n",
        "    \n",
        "  'Models':['Desicion Tree','RandomForestClassifier','LogisticRegression','LinearDiscriminantAnalysis','Naive_Bayes'],\n",
        "  'f1_score':[DTscore[2], RFscore[2], LRscore[2], LDAscore[2], NBscore[2]],\n",
        "  'recall':[DTscore[3], RFscore[3], LRscore[3], LDAscore[3], NBscore[3]],\n",
        "  'Accuracy on train set':[DTscore[0],RFscore[0],LRscore[0],LDAscore[0],NBscore[0]],\n",
        "  'Accuracy on test set':[DTscore[1], RFscore[1],LRscore[1],LDAscore[1],NBscore[1]]\n",
        "\n",
        "  })\n",
        "\n",
        "  model_compare = model_compare.sort_values('recall',ascending=False)\n",
        "  return model_compare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWY93knW1JmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03962d80-830e-4900-81b4-eddc33998ebd"
      },
      "source": [
        "# where A1C results is None\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNone, yNone, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "modelNone = modelCom(DTscore, RFscore, LRscore, LDAscore, NBscore)\n",
        "modelNone"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.89      0.69      8709\n",
            "           1       0.37      0.05      0.09      1966\n",
            "           2       0.49      0.23      0.31      5967\n",
            "\n",
            "    accuracy                           0.55     16642\n",
            "   macro avg       0.48      0.39      0.36     16642\n",
            "weighted avg       0.52      0.55      0.48     16642\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.87      0.69      8709\n",
            "           1       0.38      0.01      0.03      1966\n",
            "           2       0.48      0.26      0.34      5967\n",
            "\n",
            "    accuracy                           0.55     16642\n",
            "   macro avg       0.48      0.38      0.35     16642\n",
            "weighted avg       0.51      0.55      0.48     16642\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.00      0.00      8709\n",
            "           1       0.12      1.00      0.21      1966\n",
            "           2       0.43      0.00      0.00      5967\n",
            "\n",
            "    accuracy                           0.12     16642\n",
            "   macro avg       0.40      0.33      0.07     16642\n",
            "weighted avg       0.52      0.12      0.03     16642\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.56      0.57      8709\n",
            "           1       0.16      0.16      0.16      1966\n",
            "           2       0.40      0.42      0.41      5967\n",
            "\n",
            "    accuracy                           0.46     16642\n",
            "   macro avg       0.38      0.38      0.38     16642\n",
            "weighted avg       0.47      0.46      0.47     16642\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.80      0.69      8709\n",
            "           1       0.38      0.01      0.02      1966\n",
            "           2       0.49      0.41      0.44      5967\n",
            "\n",
            "    accuracy                           0.57     16642\n",
            "   macro avg       0.49      0.41      0.39     16642\n",
            "weighted avg       0.54      0.57      0.52     16642\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>recall</th>\n",
              "      <th>Accuracy on train set</th>\n",
              "      <th>Accuracy on test set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.567600</td>\n",
              "      <td>0.567600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.567600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.551196</td>\n",
              "      <td>0.551196</td>\n",
              "      <td>0.557441</td>\n",
              "      <td>0.551196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.483470</td>\n",
              "      <td>0.550835</td>\n",
              "      <td>0.553656</td>\n",
              "      <td>0.550835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Desicion Tree</td>\n",
              "      <td>0.465351</td>\n",
              "      <td>0.464127</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.464127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>0.119457</td>\n",
              "      <td>0.119457</td>\n",
              "      <td>0.116891</td>\n",
              "      <td>0.119457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Models  ...  Accuracy on test set\n",
              "1      RandomForestClassifier  ...              0.567600\n",
              "2          LogisticRegression  ...              0.551196\n",
              "3  LinearDiscriminantAnalysis  ...              0.550835\n",
              "0               Desicion Tree  ...              0.464127\n",
              "4                 Naive_Bayes  ...              0.119457\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ-Hhizm_OsQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "006376e5-0481-48a4-9e06-75c4595c47d3"
      },
      "source": [
        "#where A1C results is Norm\n",
        "x_train, x_test, y_train, y_test = train_test_split(xNorm, yNorm, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "modelNorm = modelCom(DTscore, RFscore, LRscore, LDAscore, NBscore)\n",
        "modelNorm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.90      0.70       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.42      0.17      0.24       284\n",
            "\n",
            "    accuracy                           0.55       817\n",
            "   macro avg       0.33      0.36      0.31       817\n",
            "weighted avg       0.46      0.55      0.46       817\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.90      0.70       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.48      0.21      0.29       284\n",
            "\n",
            "    accuracy                           0.56       817\n",
            "   macro avg       0.35      0.37      0.33       817\n",
            "weighted avg       0.48      0.56      0.48       817\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.01      0.02       445\n",
            "           1       0.10      0.93      0.19        88\n",
            "           2       0.33      0.01      0.03       284\n",
            "\n",
            "    accuracy                           0.11       817\n",
            "   macro avg       0.30      0.32      0.08       817\n",
            "weighted avg       0.37      0.11      0.04       817\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.60      0.59       445\n",
            "           1       0.10      0.10      0.10        88\n",
            "           2       0.37      0.36      0.37       284\n",
            "\n",
            "    accuracy                           0.46       817\n",
            "   macro avg       0.35      0.35      0.35       817\n",
            "weighted avg       0.46      0.46      0.46       817\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.88      0.71       445\n",
            "           1       0.00      0.00      0.00        88\n",
            "           2       0.49      0.28      0.36       284\n",
            "\n",
            "    accuracy                           0.58       817\n",
            "   macro avg       0.36      0.39      0.36       817\n",
            "weighted avg       0.50      0.58      0.51       817\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>recall</th>\n",
              "      <th>Accuracy on train set</th>\n",
              "      <th>Accuracy on test set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.575275</td>\n",
              "      <td>0.575275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.575275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.560588</td>\n",
              "      <td>0.560588</td>\n",
              "      <td>0.603466</td>\n",
              "      <td>0.560588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.464738</td>\n",
              "      <td>0.548348</td>\n",
              "      <td>0.601891</td>\n",
              "      <td>0.548348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Desicion Tree</td>\n",
              "      <td>0.461082</td>\n",
              "      <td>0.461444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.461444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>0.111383</td>\n",
              "      <td>0.111383</td>\n",
              "      <td>0.106618</td>\n",
              "      <td>0.111383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Models  ...  Accuracy on test set\n",
              "1      RandomForestClassifier  ...              0.575275\n",
              "2          LogisticRegression  ...              0.560588\n",
              "3  LinearDiscriminantAnalysis  ...              0.548348\n",
              "0               Desicion Tree  ...              0.461444\n",
              "4                 Naive_Bayes  ...              0.111383\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ176LAJ_Rgs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64c12da8-d95b-4d33-b144-ba75eb8ef1ca"
      },
      "source": [
        "#where A1C results is 7\n",
        "x_train, x_test, y_train, y_test = train_test_split(x7, y7, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "model7 = modelCom(DTscore, RFscore, LRscore, LDAscore, NBscore)\n",
        "model7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.85      0.68       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.44      0.24      0.31       221\n",
            "\n",
            "    accuracy                           0.54       624\n",
            "   macro avg       0.33      0.36      0.33       624\n",
            "weighted avg       0.46      0.54      0.48       624\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.84      0.68       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.46      0.28      0.34       221\n",
            "\n",
            "    accuracy                           0.55       624\n",
            "   macro avg       0.34      0.37      0.34       624\n",
            "weighted avg       0.47      0.55      0.49       624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.00      0.01       334\n",
            "           1       0.11      0.99      0.20        69\n",
            "           2       0.38      0.01      0.03       221\n",
            "\n",
            "    accuracy                           0.12       624\n",
            "   macro avg       0.25      0.33      0.08       624\n",
            "weighted avg       0.28      0.12      0.03       624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.58      0.59       334\n",
            "           1       0.09      0.09      0.09        69\n",
            "           2       0.38      0.39      0.38       221\n",
            "\n",
            "    accuracy                           0.46       624\n",
            "   macro avg       0.35      0.35      0.35       624\n",
            "weighted avg       0.46      0.46      0.46       624\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.84      0.69       334\n",
            "           1       0.00      0.00      0.00        69\n",
            "           2       0.48      0.32      0.38       221\n",
            "\n",
            "    accuracy                           0.56       624\n",
            "   macro avg       0.36      0.39      0.36       624\n",
            "weighted avg       0.49      0.56      0.51       624\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>recall</th>\n",
              "      <th>Accuracy on train set</th>\n",
              "      <th>Accuracy on test set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.546474</td>\n",
              "      <td>0.546474</td>\n",
              "      <td>0.596008</td>\n",
              "      <td>0.546474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.475437</td>\n",
              "      <td>0.540064</td>\n",
              "      <td>0.598073</td>\n",
              "      <td>0.540064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Desicion Tree</td>\n",
              "      <td>0.461345</td>\n",
              "      <td>0.459936</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.459936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>0.114935</td>\n",
              "      <td>0.115385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Models  ...  Accuracy on test set\n",
              "1      RandomForestClassifier  ...              0.564103\n",
              "2          LogisticRegression  ...              0.546474\n",
              "3  LinearDiscriminantAnalysis  ...              0.540064\n",
              "0               Desicion Tree  ...              0.459936\n",
              "4                 Naive_Bayes  ...              0.115385\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEJbtXyP_T6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cef11cdd-3d29-4088-934d-a39ea0f44df4"
      },
      "source": [
        "#where A1C results is 8\n",
        "x_train, x_test, y_train, y_test = train_test_split(x8, y8, test_size=0.30, random_state=1)\n",
        "LDAscore = LDA(x_train, x_test, y_test, y_train)\n",
        "LRscore = logReg(x_train, x_test, y_test, y_train)\n",
        "NBscore = navieBayes(x_train, x_test, y_test, y_train)\n",
        "DTscore = decTree(x_train, x_test, y_test, y_train)\n",
        "RFscore = ranFor(x_train, x_test, y_test, y_train)\n",
        "model8 = modelCom(DTscore, RFscore, LRscore, LDAscore, NBscore)\n",
        "model8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.84      0.71       870\n",
            "           1       0.17      0.02      0.03       162\n",
            "           2       0.50      0.34      0.41       547\n",
            "\n",
            "    accuracy                           0.58      1579\n",
            "   macro avg       0.43      0.40      0.38      1579\n",
            "weighted avg       0.53      0.58      0.54      1579\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.86      0.72       870\n",
            "           1       0.25      0.01      0.01       162\n",
            "           2       0.52      0.35      0.42       547\n",
            "\n",
            "    accuracy                           0.60      1579\n",
            "   macro avg       0.46      0.41      0.38      1579\n",
            "weighted avg       0.55      0.60      0.54      1579\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       870\n",
            "           1       0.10      0.98      0.18       162\n",
            "           2       0.48      0.02      0.04       547\n",
            "\n",
            "    accuracy                           0.11      1579\n",
            "   macro avg       0.19      0.33      0.07      1579\n",
            "weighted avg       0.18      0.11      0.03      1579\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.61      0.62       870\n",
            "           1       0.18      0.17      0.17       162\n",
            "           2       0.42      0.46      0.44       547\n",
            "\n",
            "    accuracy                           0.51      1579\n",
            "   macro avg       0.41      0.41      0.41      1579\n",
            "weighted avg       0.51      0.51      0.51      1579\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.82      0.72       870\n",
            "           1       0.00      0.00      0.00       162\n",
            "           2       0.50      0.42      0.46       547\n",
            "\n",
            "    accuracy                           0.60      1579\n",
            "   macro avg       0.38      0.41      0.39      1579\n",
            "weighted avg       0.53      0.60      0.55      1579\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>recall</th>\n",
              "      <th>Accuracy on train set</th>\n",
              "      <th>Accuracy on test set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.598480</td>\n",
              "      <td>0.598480</td>\n",
              "      <td>0.999729</td>\n",
              "      <td>0.598480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.595947</td>\n",
              "      <td>0.595947</td>\n",
              "      <td>0.603420</td>\n",
              "      <td>0.595947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>0.535166</td>\n",
              "      <td>0.582647</td>\n",
              "      <td>0.595820</td>\n",
              "      <td>0.582647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Desicion Tree</td>\n",
              "      <td>0.512657</td>\n",
              "      <td>0.511716</td>\n",
              "      <td>0.999729</td>\n",
              "      <td>0.511716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>0.106396</td>\n",
              "      <td>0.106396</td>\n",
              "      <td>0.106406</td>\n",
              "      <td>0.106396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Models  ...  Accuracy on test set\n",
              "1      RandomForestClassifier  ...              0.598480\n",
              "2          LogisticRegression  ...              0.595947\n",
              "3  LinearDiscriminantAnalysis  ...              0.582647\n",
              "0               Desicion Tree  ...              0.511716\n",
              "4                 Naive_Bayes  ...              0.106396\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}